Path Planning

Three steps:
 *Prediction: Estimating what other vehicles on a road might do next
 *Behaviour: Decide what maneuver to do next given estimates from prediction
 *Trajectory: Select path to follow given chosen behaviour.

1. Discrete Path Planning
 *Motivation: Worth learning about (1) conceptually and (2) practically because discretising the world makes it easier and computationally faster to solve path planning problems
1.1 Motion Planning
 *Problem: Want to get from A to B.
  *Difficult because mechanics within the path, e.g. lane shifting, might be risky and so you might not choose the most direct path.
 *Given: Map, Starting location, goal location, cost function, Find: minimum cost path.
 *Varying cost functions, e.g.:
  *Count left turn + and move one step forward as one move vs only left turn on the spot as one move
  *Left turns may be more expensive than right turns (because of congestion or traffic rules)
1.2 Path planning as a search problem
 *Without uncertainty:
  *Find the shortest sequence of actions that leads robot from start state to end state
1.3 Writing a search program
 *Open List: List of states (we've been in?) -> expand states in open list.
  *G-value (of a state): number of expansions it took to get to each state in the open list
  *Expand states with the smallest g-value
1.4 A* (finds a path)
 *Often uses a smaller number of expansions compared to without A* because you take into account additional information, e.g. the direct distance from the node to the goal state.
 *F-value: f = g + h(x,y)
 *Remove the element with the lowest f-value instead of the lowest g-value
  *h(x,y) is a heuristic function: gives a value for each cell.
   *E.g. number of steps it takes to get to the goal if there are no obstacles.
   *Helps you understand where to search next in case of ties 1.4
 *Used in the DARPA Grand Challenge.
1.5 Dynamic Programming (finds a policy)
 *Given:
  *Map
  *Goal
  *Outputs:
 *Best path from anywhere.
  *A policy: a function that specifies an action for each position (x,y).
 *Motivation: if environment is stochastic (unpredictable).
  *Then an action involved in original plan to get to destination may fail.
  *-> may need to plan for other positions as well.
 *Implementing Dynamic Programming for Robot Path Planning
  *A value function associates each grid cell with the length of the shortest path from the cell to the goal.
  *calculated recursively
  *Implement program that prints value.
  *Implement program that prints optimal policy.
1.6 Left Turn Policy: Adding orientation to the state
 *Add orientation to the state (previously just (x,y)) so state is three dimensional.
 *Now assign different costs to different actions.